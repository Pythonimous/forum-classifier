{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.09677419, 0.        , 0.06451613, ..., 0.00420168, 0.05042017,\n",
       "        0.07142857],\n",
       "       [0.05      , 0.        , 0.        , ..., 0.01459854, 0.05839416,\n",
       "        0.06569343],\n",
       "       [0.14285715, 0.04081633, 0.02040816, ..., 0.01604278, 0.05614973,\n",
       "        0.05882353],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.00406504, 0.05691057,\n",
       "        0.07317073],\n",
       "       [0.01587302, 0.01587302, 0.        , ..., 0.00429185, 0.07296138,\n",
       "        0.06866953],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.1       ,\n",
       "        0.05555556]], dtype=float32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('Train_twenty.pkl', 'rb') as tr:\n",
    "    X_train = pkl.load(tr)\n",
    "tr.close()\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01941748, 0.        , 0.        , ..., 0.00387597, 0.04134367,\n",
       "        0.05297158],\n",
       "       [0.0625    , 0.        , 0.0625    , ..., 0.00769231, 0.03846154,\n",
       "        0.06923077],\n",
       "       [0.09090909, 0.03030303, 0.        , ..., 0.0037037 , 0.01851852,\n",
       "        0.07037037],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.08074534,\n",
       "        0.03726708],\n",
       "       [0.        , 0.02380952, 0.        , ..., 0.00527705, 0.05013192,\n",
       "        0.06860159],\n",
       "       [0.01666667, 0.00833333, 0.        , ..., 0.00221484, 0.03543743,\n",
       "        0.04318937]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('Val_twenty.pkl', 'rb') as val:\n",
    "    X_val = pkl.load(val)\n",
    "val.close()\n",
    "X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04761905, 0.        , 0.        , ..., 0.0030581 , 0.06116208,\n",
       "        0.06116208],\n",
       "       [0.20833333, 0.        , 0.04166667, ..., 0.        , 0.07058824,\n",
       "        0.05882353],\n",
       "       [0.12903225, 0.        , 0.03225806, ..., 0.        , 0.05785124,\n",
       "        0.04545455],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.00422833, 0.03171247,\n",
       "        0.06553911],\n",
       "       [0.        , 0.        , 0.02777778, ..., 0.00386399, 0.03323029,\n",
       "        0.04250386],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.04347826,\n",
       "        0.04347826]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('Test_twenty.pkl', 'rb') as test:\n",
    "    X_test = pkl.load(test)\n",
    "test.close()\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87844"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('Train_labels.txt', 'r') as l:\n",
    "    train_labels = l.read().split('\\n')\n",
    "l.close()\n",
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('Val_labels.txt', 'r') as v:\n",
    "    val_labels = v.read().split('\\n')\n",
    "v.close()\n",
    "len(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('Test_labels.txt', 'r') as t:\n",
    "    test_labels = t.read().split('\\n')\n",
    "t.close()\n",
    "len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BAYES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, ComplementNB, BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gauss = GaussianNB()\n",
    "gauss.fit(X_train, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.623, 0.606)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gauss.score(X_val, val_labels), gauss.score(X_test, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[60,  2,  0,  1,  0,  0,  0,  3,  0,  2],\n",
       "       [ 4, 75,  1,  1,  0,  1,  2,  1,  4,  4],\n",
       "       [ 3,  1, 69,  7,  5,  0,  7,  3,  0,  6],\n",
       "       [ 2,  5,  3, 64,  0,  0,  3,  5,  0,  4],\n",
       "       [ 1,  2,  1,  0, 80,  1,  1,  3, 21, 10],\n",
       "       [ 2,  2,  6,  6,  2, 89, 15, 12,  6, 23],\n",
       "       [24, 10, 14, 15,  5,  7, 66, 13, 22, 28],\n",
       "       [ 1,  0,  4,  5,  2,  2,  6, 57, 19,  1],\n",
       "       [ 1,  2,  1,  1,  2,  0,  0,  3, 24,  0],\n",
       "       [ 2,  1,  1,  0,  4,  0,  0,  0,  4, 22]], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(gauss.predict(X_test), test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Anime       0.60      0.88      0.71        68\n",
      "         Art       0.75      0.81      0.78        93\n",
      "       Books       0.69      0.68      0.69       101\n",
      "       Films       0.64      0.74      0.69        86\n",
      "        Food       0.80      0.67      0.73       120\n",
      "    Football       0.89      0.55      0.68       163\n",
      "       Games       0.66      0.32      0.43       204\n",
      "       Music       0.57      0.59      0.58        97\n",
      "      Nature       0.24      0.71      0.36        34\n",
      "      Travel       0.22      0.65      0.33        34\n",
      "\n",
      "    accuracy                           0.61      1000\n",
      "   macro avg       0.61      0.66      0.60      1000\n",
      "weighted avg       0.68      0.61      0.62      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(gauss.predict(X_test), test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multinom = MultinomialNB()\n",
    "multinom.fit(X_train, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.135, 0.131)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multinom.score(X_val, val_labels), multinom.score(X_test, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.641"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multinom.fit(X_val, val_labels)\n",
    "multinom.score(X_test, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Anime       0.71      0.77      0.74        92\n",
      "         Art       0.67      0.88      0.76        76\n",
      "       Books       0.73      0.74      0.74        98\n",
      "       Films       0.72      0.70      0.71       103\n",
      "        Food       0.70      0.80      0.74        88\n",
      "    Football       0.73      0.69      0.71       106\n",
      "       Games       0.47      0.47      0.47        99\n",
      "       Music       0.49      0.64      0.56        76\n",
      "      Nature       0.53      0.47      0.50       112\n",
      "      Travel       0.66      0.44      0.53       150\n",
      "\n",
      "    accuracy                           0.64      1000\n",
      "   macro avg       0.64      0.66      0.65      1000\n",
      "weighted avg       0.64      0.64      0.64      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(multinom.predict(X_test), test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[71,  4,  0,  1,  4,  1,  5,  2,  2,  2],\n",
       "       [ 2, 67,  0,  0,  0,  0,  0,  0,  4,  3],\n",
       "       [ 2,  3, 73,  5,  1,  0,  4,  2,  2,  6],\n",
       "       [ 1,  4,  8, 72,  0,  1,  2,  8,  2,  5],\n",
       "       [ 2,  0,  0,  0, 70,  0,  0,  1, 11,  4],\n",
       "       [ 5,  3,  3,  4,  3, 73,  4,  5,  0,  6],\n",
       "       [ 4,  6,  8,  6,  5,  6, 47,  9,  3,  5],\n",
       "       [ 1,  1,  1,  1,  3,  3,  4, 49, 12,  1],\n",
       "       [ 3,  6,  1,  6,  7,  9,  8, 17, 53,  2],\n",
       "       [ 9,  6,  6,  5,  7,  7, 26,  7, 11, 66]], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(multinom.predict(X_test), test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ComplementNB(alpha=1.0, class_prior=None, fit_prior=True, norm=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp = ComplementNB()\n",
    "comp.fit(X_train, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.545, 0.532)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp.score(X_val, val_labels), comp.score(X_test, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Anime       0.51      0.84      0.63        61\n",
      "         Art       0.47      0.87      0.61        54\n",
      "       Books       0.77      0.54      0.63       143\n",
      "       Films       0.70      0.62      0.66       113\n",
      "        Food       0.80      0.59      0.68       136\n",
      "    Football       0.82      0.50      0.62       165\n",
      "       Games       0.71      0.37      0.49       192\n",
      "       Music       0.54      0.40      0.46       136\n",
      "      Nature       0.00      0.00      0.00         0\n",
      "      Travel       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.53      1000\n",
      "   macro avg       0.53      0.47      0.48      1000\n",
      "weighted avg       0.70      0.53      0.59      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\1\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(comp.predict(X_test), test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.594"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp.fit(X_val, val_labels).score(X_test, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bern = BernoulliNB()\n",
    "bern.fit(X_train, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.449, 0.425)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bern.score(X_val, val_labels), bern.score(X_test, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Anime       0.20      0.71      0.31        28\n",
      "         Art       0.34      0.61      0.44        56\n",
      "       Books       0.65      0.41      0.51       157\n",
      "       Films       0.50      0.47      0.48       107\n",
      "        Food       0.66      0.61      0.63       108\n",
      "    Football       0.76      0.48      0.59       158\n",
      "       Games       0.76      0.26      0.39       290\n",
      "       Music       0.38      0.40      0.39        94\n",
      "      Nature       0.00      0.00      0.00         2\n",
      "      Travel       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.42      1000\n",
      "   macro avg       0.42      0.40      0.37      1000\n",
      "weighted avg       0.63      0.42      0.48      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\1\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(bern.predict(X_test), test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.504"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bern.fit(X_val, val_labels).score(X_test, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Anime       0.53      0.55      0.54        97\n",
      "         Art       0.68      0.58      0.62       118\n",
      "       Books       0.58      0.51      0.54       113\n",
      "       Films       0.63      0.51      0.56       124\n",
      "        Food       0.68      0.59      0.63       116\n",
      "    Football       0.64      0.61      0.62       105\n",
      "       Games       0.48      0.41      0.44       116\n",
      "       Music       0.35      0.45      0.40        77\n",
      "      Nature       0.34      0.39      0.36        88\n",
      "      Travel       0.13      0.28      0.18        46\n",
      "\n",
      "    accuracy                           0.50      1000\n",
      "   macro avg       0.50      0.49      0.49      1000\n",
      "weighted avg       0.54      0.50      0.52      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(bern.predict(X_test), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsvc = LinearSVC(random_state=0, tol=1e-4)\n",
    "lsvc.fit(X_train, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.523, 0.523)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsvc.score(X_val, val_labels), lsvc.score(X_test, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.647"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsvc.fit(X_val, val_labels).score(X_test, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[77,  4,  0,  1,  4,  1, 11,  5,  2,  3],\n",
       "       [ 2, 74,  0,  1,  0,  0,  0,  2,  4,  3],\n",
       "       [ 4,  2, 76,  6,  3,  2,  7,  5,  5,  8],\n",
       "       [ 1,  4,  8, 75,  0,  1,  3,  9,  1,  6],\n",
       "       [ 3,  0,  0,  0, 77,  0,  0,  0, 16,  9],\n",
       "       [ 2,  2,  6,  4,  2, 76,  5,  7,  2,  8],\n",
       "       [ 5,  8,  5,  5,  5, 10, 49,  9,  5,  8],\n",
       "       [ 0,  0,  1,  3,  4,  4,  4, 52, 18,  2],\n",
       "       [ 3,  4,  2,  1,  3,  2,  4,  7, 38,  0],\n",
       "       [ 3,  2,  2,  4,  2,  4, 17,  4,  9, 53]], dtype=int64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(lsvc.predict(X_test), test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Anime       0.77      0.71      0.74       108\n",
      "         Art       0.74      0.86      0.80        86\n",
      "       Books       0.76      0.64      0.70       118\n",
      "       Films       0.75      0.69      0.72       108\n",
      "        Food       0.77      0.73      0.75       105\n",
      "    Football       0.76      0.67      0.71       114\n",
      "       Games       0.49      0.45      0.47       109\n",
      "       Music       0.52      0.59      0.55        88\n",
      "      Nature       0.38      0.59      0.46        64\n",
      "      Travel       0.53      0.53      0.53       100\n",
      "\n",
      "    accuracy                           0.65      1000\n",
      "   macro avg       0.65      0.65      0.64      1000\n",
      "weighted avg       0.66      0.65      0.65      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(lsvc.predict(X_test), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K nearest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kn = KNeighborsClassifier()\n",
    "kn.fit(X_train, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.553, 0.54)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kn.score(X_val, val_labels), kn.score(X_test, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.581"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kn.fit(X_val, val_labels).score(X_test, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators = 100)\n",
    "rfc.fit(X_train, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.574, 0.561)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.score(X_val, val_labels), rfc.score(X_test, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6506506506506506"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.fit(X_val, val_labels).score(X_test, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Anime       0.56      0.93      0.70        60\n",
      "         Art       0.52      0.88      0.65        59\n",
      "       Books       0.73      0.70      0.72       104\n",
      "       Films       0.64      0.75      0.69        85\n",
      "        Food       0.78      0.72      0.75       108\n",
      "    Football       0.82      0.59      0.69       139\n",
      "       Games       0.87      0.27      0.41       323\n",
      "       Music       0.49      0.49      0.49       101\n",
      "      Nature       0.10      0.91      0.18        11\n",
      "      Travel       0.10      1.00      0.18        10\n",
      "\n",
      "    accuracy                           0.56      1000\n",
      "   macro avg       0.56      0.72      0.55      1000\n",
      "weighted avg       0.73      0.56      0.58      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(rfc.predict(X_test), test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl1 = MultinomialNB()\n",
    "cl2 = LinearSVC()\n",
    "cl3 = RandomForestClassifier(n_estimators = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "vt = VotingClassifier(estimators = [('nb', cl1), ('svc', cl2), ('rfc', cl3)], voting='hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('nb',\n",
       "                              MultinomialNB(alpha=1.0, class_prior=None,\n",
       "                                            fit_prior=True)),\n",
       "                             ('svc',\n",
       "                              LinearSVC(C=1.0, class_weight=None, dual=True,\n",
       "                                        fit_intercept=True, intercept_scaling=1,\n",
       "                                        loss='squared_hinge', max_iter=1000,\n",
       "                                        multi_class='ovr', penalty='l2',\n",
       "                                        random_state=None, tol=0.0001,\n",
       "                                        verbose=0)),\n",
       "                             ('rfc',\n",
       "                              RandomForestClassifier(bootstrap=True,\n",
       "                                                     class_weight=None,\n",
       "                                                     criterion='gini',\n",
       "                                                     max_depth=None,\n",
       "                                                     max_features='auto',\n",
       "                                                     max_leaf_nodes=None,\n",
       "                                                     min_impurity_decrease=0.0,\n",
       "                                                     min_impurity_split=None,\n",
       "                                                     min_samples_leaf=1,\n",
       "                                                     min_samples_split=2,\n",
       "                                                     min_weight_fraction_leaf=0.0,\n",
       "                                                     n_estimators=100,\n",
       "                                                     n_jobs=None,\n",
       "                                                     oob_score=False,\n",
       "                                                     random_state=None,\n",
       "                                                     verbose=0,\n",
       "                                                     warm_start=False))],\n",
       "                 flatten_transform=True, n_jobs=None, voting='hard',\n",
       "                 weights=None)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vt.fit(X_train, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.518, 0.528)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vt.score(X_val, val_labels), vt.score(X_test, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vt.fit(X_val, val_labels).score(X_test, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Anime       0.76      0.72      0.74       105\n",
      "         Art       0.73      0.86      0.79        85\n",
      "       Books       0.77      0.71      0.74       108\n",
      "       Films       0.74      0.70      0.72       105\n",
      "        Food       0.75      0.74      0.74       102\n",
      "    Football       0.75      0.69      0.72       109\n",
      "       Games       0.51      0.46      0.49       110\n",
      "       Music       0.53      0.63      0.58        84\n",
      "      Nature       0.46      0.57      0.51        81\n",
      "      Travel       0.60      0.54      0.57       111\n",
      "\n",
      "    accuracy                           0.66      1000\n",
      "   macro avg       0.66      0.66      0.66      1000\n",
      "weighted avg       0.67      0.66      0.66      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(vt.predict(X_test), test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
