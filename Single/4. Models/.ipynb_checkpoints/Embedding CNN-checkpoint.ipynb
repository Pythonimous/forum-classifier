{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Train_lemmas.txt', 'r', encoding='utf-8') as t:\n",
    "    train_lem = t.read().split('\\n')\n",
    "t.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Val_lemmas.txt', 'r', encoding='utf-8') as t:\n",
    "    val_lem = t.read().split('\\n')\n",
    "t.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Test_lemmas.txt', 'r', encoding='utf-8') as t:\n",
    "    test_lem = t.read().split('\\n')\n",
    "t.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121484"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_lem_count = len(set(' '.join(train_lem).split()))\n",
    "train_lem_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38.99672146077137"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([len(a.split()) for a in train_lem])/len(train_lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Train_twenty.pkl', 'rb') as tr:\n",
    "    X_train_20 = pkl.load(tr)\n",
    "tr.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Val_twenty.pkl', 'rb') as val:\n",
    "    X_val_20 = pkl.load(val)\n",
    "val.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Test_twenty.pkl', 'rb') as test:\n",
    "    X_test_20 = pkl.load(test)\n",
    "test.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87844"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('Train_labels.txt', 'r') as l:\n",
    "    train_labels = l.read().split('\\n')\n",
    "l.close()\n",
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('Val_labels.txt', 'r') as v:\n",
    "    val_labels = v.read().split('\\n')\n",
    "v.close()\n",
    "len(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('Test_labels.txt', 'r') as t:\n",
    "    test_labels = t.read().split('\\n')\n",
    "t.close()\n",
    "len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "enc = LabelEncoder()\n",
    "enc.fit(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87844,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_labels = enc.transform(train_labels)\n",
    "y_train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_labels = enc.transform(val_labels)\n",
    "y_val_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_labels = enc.transform(test_labels)\n",
    "y_test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import Model, metrics\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Dense, Dropout, Flatten, Input, Concatenate, Conv1D, MaxPooling1D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87844, 10)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = to_categorical(y_train_labels)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 10)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val = to_categorical(y_val_labels)\n",
    "y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 10)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = to_categorical(y_test_labels)\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 121484\n",
    "#num_words = train_lem_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=num_words)\n",
    "tokenizer.fit_on_texts(train_lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_300 = tokenizer.texts_to_sequences(train_lem)\n",
    "X_val_300 = tokenizer.texts_to_sequences(val_lem)\n",
    "X_test_300 = tokenizer.texts_to_sequences(test_lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1  # Adding 1 because of reserved 0 index\n",
    "embedding_size = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 100\n",
    "\n",
    "X_train_300 = pad_sequences(X_train_300, padding='post', maxlen=maxlen)\n",
    "X_val_300 = pad_sequences(X_val_300, padding='post', maxlen=maxlen)\n",
    "X_test_300 = pad_sequences(X_test_300, padding='post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the label encoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Fit the label encoder to our label series\n",
    "le.fit(list(y_train_labels))\n",
    "\n",
    "# Create integer based labels Series\n",
    "y_integers = le.transform(list(y_train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = compute_class_weight('balanced', np.unique(y_train_labels), y_train_labels)\n",
    "class_weights_dict = dict(zip(le.transform(list(le.classes_)), class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "batch_size = 512\n",
    "epochs = 100\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputA = Input(shape=(maxlen,))\n",
    "inputB = Input(shape=(20,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = Embedding(output_dim=embedding_size, input_dim=num_words, input_length=maxlen, trainable = True)(inputA)\n",
    "x = Conv1D(26, 10, activation='relu')(emb)\n",
    "x = MaxPooling1D(2)(x)\n",
    "x = Flatten()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Model(inputs = inputA, outputs = x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = Dense(20, activation=\"relu\")(inputB)\n",
    "y = Dense(10, activation=\"relu\")(y)\n",
    "y = Model(inputs=inputB, outputs = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = Concatenate()([x.output, y.output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = Dense(200, activation='relu')(combined)\n",
    "z = Dense(100, activation='relu')(combined)\n",
    "z = Dense(num_classes, activation='softmax')(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs =[x.input, y.input], outputs = z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 100, 300)     36445200    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 91, 26)       78026       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 45, 26)       0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 1170)         0           max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 20)           420         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1170)         0           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           210         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1180)         0           dropout_1[0][0]                  \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 100)          118100      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 10)           1010        dense_4[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 36,642,966\n",
      "Trainable params: 36,642,966\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=[metrics.categorical_accuracy])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop = EarlyStopping(monitor='val_categorical_accuracy', min_delta = 0.0001, patience=5, verbose=1, mode='auto')\n",
    "callbacks_list = [earlystop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 87844 samples, validate on 1000 samples\n",
      "Epoch 1/100\n",
      "87844/87844 [==============================] - 164s 2ms/step - loss: 1.3177 - categorical_accuracy: 0.5758 - val_loss: 0.4452 - val_categorical_accuracy: 0.8540\n",
      "Epoch 2/100\n",
      "87844/87844 [==============================] - 163s 2ms/step - loss: 0.2433 - categorical_accuracy: 0.9420 - val_loss: 0.4080 - val_categorical_accuracy: 0.8700\n",
      "Epoch 3/100\n",
      "87844/87844 [==============================] - 163s 2ms/step - loss: 0.0576 - categorical_accuracy: 0.9827 - val_loss: 0.4842 - val_categorical_accuracy: 0.8700\n",
      "Epoch 4/100\n",
      "87844/87844 [==============================] - 163s 2ms/step - loss: 0.0219 - categorical_accuracy: 0.9934 - val_loss: 0.5659 - val_categorical_accuracy: 0.8600\n",
      "Epoch 5/100\n",
      "87844/87844 [==============================] - 164s 2ms/step - loss: 0.0136 - categorical_accuracy: 0.9967 - val_loss: 0.6231 - val_categorical_accuracy: 0.8560\n",
      "Epoch 6/100\n",
      "87844/87844 [==============================] - 163s 2ms/step - loss: 0.0102 - categorical_accuracy: 0.9979 - val_loss: 0.6423 - val_categorical_accuracy: 0.8550\n",
      "Epoch 7/100\n",
      "87844/87844 [==============================] - 163s 2ms/step - loss: 0.0085 - categorical_accuracy: 0.9984 - val_loss: 0.7006 - val_categorical_accuracy: 0.8520\n",
      "Epoch 00007: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7feab2589cf8>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([X_train_300, X_train_20], y_train, batch_size=batch_size, epochs=epochs, callbacks=callbacks_list,\n",
    "          validation_data=([X_val_300, X_val_20], y_val), class_weight = class_weights_dict, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.700622999528423\n",
      "Val accuracy: 0.852\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate([X_val_300, X_val_20], y_val, verbose=0)\n",
    "print('Val loss:', scores[0])\n",
    "print('Val accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[77,  0,  0,  0,  1,  0,  0,  1,  0,  0],\n",
       "       [ 0, 69,  1,  0,  0,  0,  0,  0,  2,  2],\n",
       "       [ 5, 10, 96,  2,  0,  0,  0,  0,  1,  0],\n",
       "       [ 7,  4,  1, 86,  1,  0,  3,  4,  2,  3],\n",
       "       [ 0,  1,  0,  0, 96,  0,  0,  0, 13,  4],\n",
       "       [ 2,  2,  0,  0,  0, 97,  1,  2,  1,  4],\n",
       "       [ 4,  4,  1,  6,  2,  2, 94,  1,  7,  1],\n",
       "       [ 5,  3,  0,  6,  0,  1,  1, 92,  1,  4],\n",
       "       [ 0,  5,  1,  0,  0,  0,  1,  0, 65,  2],\n",
       "       [ 0,  2,  0,  0,  0,  0,  0,  0,  8, 80]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict([X_val_300, X_val_20])\n",
    "y_pred_classes = [[1 if c == max(a) else 0 for c in a] for a in y_pred]\n",
    "y_pred_labels = [a.index(1) for a in y_pred_classes]\n",
    "confusion_matrix(y_pred_labels, y_val_labels)\n",
    "#y_val_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.8315693635940552\n",
      "Test accuracy: 0.838\n"
     ]
    }
   ],
   "source": [
    "test_scores = model.evaluate([X_test_300, X_test_20], y_test, verbose=0)\n",
    "print('Test loss:', test_scores[0])\n",
    "print('Test accuracy:', test_scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[78,  5,  0,  9,  1,  0,  6,  8,  2,  0],\n",
       "       [ 1, 63,  1,  1,  0,  0,  0,  0,  4,  2],\n",
       "       [ 3,  6, 88,  4,  0,  0,  1,  0,  4,  2],\n",
       "       [ 2, 14,  2, 70,  1,  0,  0,  9,  3,  1],\n",
       "       [ 3,  2,  1,  1, 89,  0,  0,  0, 14,  2],\n",
       "       [ 1,  0,  0,  1,  2, 95,  1,  0,  3,  0],\n",
       "       [10,  2,  5, 11,  0,  3, 91,  5,  1,  2],\n",
       "       [ 2,  2,  1,  2,  0,  0,  0, 75,  2,  1],\n",
       "       [ 0,  3,  0,  1,  5,  1,  1,  2, 55,  3],\n",
       "       [ 0,  3,  2,  0,  2,  1,  0,  1, 12, 87]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict([X_test_300, X_test_20])\n",
    "y_pred_classes = [[1 if c == max(a) else 0 for c in a] for a in y_pred]\n",
    "y_pred_labels = [a.index(1) for a in y_pred_classes]\n",
    "confusion_matrix(y_pred_labels, y_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.72      0.75       109\n",
      "           1       0.63      0.88      0.73        72\n",
      "           2       0.88      0.81      0.85       108\n",
      "           3       0.70      0.69      0.69       102\n",
      "           4       0.89      0.79      0.84       112\n",
      "           5       0.95      0.92      0.94       103\n",
      "           6       0.91      0.70      0.79       130\n",
      "           7       0.75      0.88      0.81        85\n",
      "           8       0.55      0.77      0.64        71\n",
      "           9       0.87      0.81      0.84       108\n",
      "\n",
      "    accuracy                           0.79      1000\n",
      "   macro avg       0.79      0.80      0.79      1000\n",
      "weighted avg       0.81      0.79      0.79      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred_labels, y_test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(model, to_file='model_plot cnn.png', show_shapes=True, show_layer_names=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
